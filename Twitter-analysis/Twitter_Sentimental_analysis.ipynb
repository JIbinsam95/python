{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Analysis \n",
    "\n",
    "* getting tweets\n",
    "\n",
    "* cleaning Tweets\n",
    "\n",
    "* saving in MongoDB\n",
    "\n",
    "* Sentiment Analysis using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tweepy\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import jdc \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Class\n",
    "\n",
    "Class Tweet retrieve Tweets\n",
    "\n",
    "*  load_api() to initialise Twitter App\n",
    "*  create_db() to create database and retrieve tweets  from the mongoDB \n",
    "*  get_tweet() to query \n",
    "*  save_tweet() to save tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "\n",
    "    #Api_call\n",
    "    def load_api(self):\n",
    "        CONSUMER_KEY = 'Consumer Key'\n",
    "        CONSUMER_SECRET = 'Consumer secret'\n",
    "        oAuthToken = 'Authorisation Token'\n",
    "        OAUTH_TOKEN_SECRET= 'authorisation token secret key'\n",
    "        auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(oAuthToken, OAUTH_TOKEN_SECRET)\n",
    "        return tweepy.API(auth) \n",
    "    \n",
    "    #creating a db in mongodb\n",
    "    def create_db(self):\n",
    "        self.client = MongoClient()\n",
    "        self.dbNames=self.client.list_database_names()\n",
    "        if \"tweet_db\" in self.dbNames:\n",
    "            self.db=self.client.tweet_db\n",
    "            self.tcollection=self.db.tweet_collection\n",
    "            self.pointer=self.tcollection.find({})\n",
    "            return self.pointer\n",
    "            \n",
    "        else:\n",
    "            self.db=self.client.tweet_db\n",
    "            self.t_collection=self.db.tweet_collection\n",
    "            self.t_collection.create_index([(\"id\",pymongo.ASCENDING)],unique=True)\n",
    "            self.get_tweet()\n",
    "        \n",
    "        #query needed for the api call\n",
    "    def get_tweet(self):\n",
    "        self.query=\"ozil\"\n",
    "        self.Ap=self.load_api()\n",
    "        self.results=self.Ap.search(q= self.query)\n",
    "        #for r in results:\n",
    "            #print(r)\n",
    "        self.save_tweet()\n",
    "    \n",
    "    #inserting required attributes in db\n",
    "    def save_tweet(self):\n",
    "        for r in self.results:\n",
    "            self.individual_tweet=({\"id\":r.id,\"user_id\":r.user.id,\"tweet_text\":r.text,\"created_at\":r.created_at})\n",
    "            self.t_collection.insert_one(self.individual_tweet)\n",
    "        #pointer = self.t_collection.find({})\n",
    "        #for p in pointer: \n",
    "         #   pprint(p)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to Clean the data\n",
    "*  clean() cleaning the data by removing hashtags,@, Urls, emojis etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Data_Cleaner(Tweet):\n",
    "    \n",
    "    def clean(self):\n",
    "        self.db_pointer=Tweet.create_db(self)     \n",
    "        try:\n",
    " \n",
    "            #cleaning the data\n",
    "            for p in self.db_pointer:\n",
    "                temp_tweet=p[\"tweet_text\"]\n",
    "                        #removing hashtags replacement #\n",
    "                p[\"tweet_text\"] = re.sub(r'#\\w+ ?', '#', p['tweet_text'])\n",
    "                     #removing urls replacement URL\n",
    "                p[\"tweet_text\"] = re.sub(r'http\\S+', 'URL', p['tweet_text'])\n",
    "                        #removing tags -replacement @\n",
    "                p[\"tweet_text\"] = re.sub(r'@[a-zA-Z0-9]+','@', p['tweet_text'])\n",
    "                    \n",
    "                p[\"tweet_text\"] = re.sub(r'@_[a-zA-Z0-9]_+','@', p['tweet_text'])\n",
    "                        \n",
    "                    #removing emojis-replacement **\n",
    "                                          \n",
    "                remove_emoji = re.compile(u'['\n",
    "                                                    u'\\U0001F300-\\U0001F64F'\n",
    "                                                    u'\\U0001F680-\\U0001F6FF'\n",
    "                                                    u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "                                                    re.UNICODE)\n",
    "                p[\"tweet_text\"]=remove_emoji.sub(\"**\",p[\"tweet_text\"])\n",
    "                    \n",
    "                \n",
    "                #print(p[\"tweet_text\"])\n",
    "                myquery= {\"tweet_text\":temp_tweet}\n",
    "                newvalues={\"$set\":{\"tweet_text\":p[\"tweet_text\"]}}\n",
    "                tweet_len={\"$set\":{\"len\":len(p[\"tweet_text\"])}}\n",
    "                self.tcollection.update_one(myquery,newvalues)\n",
    "                self.tcollection.update_one(myquery,tweet_len)\n",
    "                     \n",
    "        except:\n",
    "            print(\"Error while Cleaning the data\")\n",
    "            pass\n",
    "        \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to analyse the Tweets\n",
    "*  analyze() uses the TextBlob to find the sentiment and catagorise the tweets into positiv,negative or neutral and also updating the Mongo collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Analyser(Data_Cleaner):\n",
    "    \n",
    "    def analyze(self):\n",
    "        \n",
    "        polarity_list = []\n",
    "        tweet1 = []\n",
    "        number = 1\n",
    "        db_pointer=Tweet.create_db(self)\n",
    "        df=pd.DataFrame(list(db_pointer))\n",
    "        #print(df[\"tweet_text\"])\n",
    "        for item in df[\"tweet_text\"] :\n",
    "            #tweet=Tweet.clean(self,item)\n",
    "            try:\n",
    "                analysis = TextBlob(item)\n",
    "                analysis = analysis.sentiment\n",
    "                polarity = analysis.polarity\n",
    "                tweet1.append(item)\n",
    "                    \n",
    "                if(polarity>0):\n",
    "                    sentiment_value= 'positive'\n",
    "                elif(polarity==0):\n",
    "                    sentiment_value ='neutral'\n",
    "                else:\n",
    "                    sentiment_value= 'negative'    \n",
    "                    \n",
    "                polarity_list.append(sentiment_value) \n",
    "                \n",
    "                myquery= {\"tweet_text\":item}\n",
    "                newvalues={\"$set\":{\"Sentiment Value\":sentiment_value}}\n",
    "                self.tcollection.update_one(myquery,newvalues)\n",
    "            except:\n",
    "                print(\"errorr\")\n",
    "        \n",
    "        \n",
    "        #outputDF=pd.DataFrame({'Tweet':tweet_list,'Sentiment_value':polarity_list})\n",
    "        #print(outputDF)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "                                     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    t=Tweet()\n",
    "    t.create_db()\n",
    "    dc=Data_Cleaner()\n",
    "    dc.clean()\n",
    "    da=Data_Analyser()\n",
    "    da.analyze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
